{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9L_hUyrn2Ab"
      },
      "source": [
        "# Transformer Base ChatBot From Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g39oID8n2Ac"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAyi_3MMq6v7",
        "outputId": "07a771a2-6591-48c1-feb5-80b1e26618bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: spire.doc in /lustre/fs1/home/ssheikholeslami/.local/lib/python3.8/site-packages (12.3.2)\n",
            "Requirement already satisfied: plum-dispatch==1.7.4 in /lustre/fs1/home/ssheikholeslami/.local/lib/python3.8/site-packages (from spire.doc) (1.7.4)\n"
          ]
        }
      ],
      "source": [
        "# installs for functionality\n",
        "!pip install spire.doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dDZ0kPLn2Ad",
        "outputId": "ba8f566e-5a92-4f06-a49a-5a5693072573"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/ssheikholeslami/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /home/ssheikholeslami/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/ssheikholeslami/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# # imports for text analysis and organization\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bs4 import BeautifulSoup\n",
        "import collections\n",
        "from collections import Counter\n",
        "import wordcloud\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from re import sub\n",
        "from re import compile\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# GPU information\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcGHvdYYn2Ad"
      },
      "source": [
        "## Loading DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mgnsHy7In2Ad"
      },
      "outputs": [],
      "source": [
        "# universal data loading\n",
        "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txBlock - not nessecary will use book\n",
        "# attempt to load in book as corpus\n",
        "corpuspath = './Speech and Language processing.txt'\n",
        "\n",
        "# Read in statements for sample data\n",
        "# read it in to inspect it\n",
        "with open(corpuspath, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owve30nFcI7b"
      },
      "source": [
        "## Exploratory Data Analysis - Book Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5vL1D3bn2Ae",
        "outputId": "e5e807b9-0a36-40b7-d2ae-1c73fa53650b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "how many characters we have:  1918701\n",
            "Speech and Language Processing \n",
            "\n",
            "An Introduction to Natural Language Processing, \n",
            "Computational Linguistics, and Speech Recognition \n",
            "\n",
            "Third Edition draft \n",
            "\n",
            "Daniel Jurafsky \n",
            "\n",
            "Stanford University \n",
            "\n",
            "James H. Martin \n",
            "\n",
            "University of Colorado at Boulder \n",
            "\n",
            "Copyright ©2023. All rights reserved. \n",
            "\n",
            "Draft of January 7, 2023. Comments and typos welcome! \n",
            "\n",
            "\f\n",
            "Summary of Contents \n",
            "\n",
            "I Fundamental Algorithms for NLP 1 \n",
            "1 Introduction. .................................................. 3 \n",
            "2 Regular Expressions, T\n"
          ]
        }
      ],
      "source": [
        "# data prelimnary analysis\n",
        "print(\"how many characters we have: \", len(text))\n",
        "\n",
        "## Inspect the first 500 characters\n",
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqnHSMtLn2Ae",
        "outputId": "9e20dbce-eff6-4c41-c831-118b06e26216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speech and Language Processing \n",
            "\n",
            "An Introduction to Natural Language Processing, \n",
            "Computational Linguistics, and Speech Recognition \n",
            "\n",
            "Third Edition draft \n",
            "\n",
            "Daniel Jurafsky \n",
            "\n",
            "Stanford University \n",
            "\n",
            "James H. Martin \n",
            "\n",
            "University of Colorado at Boulder \n",
            "\n",
            "Copyright . All rights reserved. \n",
            "\n",
            "Draft of January , . Comments and typos welcome! \n",
            "\n",
            " \n",
            "Summary of Contents \n",
            "\n",
            "I Fundamental Algorithms for NLP \n",
            " Introduction. .................................................. \n",
            " Regular Expressions, Text Normalization, Edit Distance . . . . . . . . . \n",
            " N-gramLanguageModels ..................................... \n",
            " Naive Bayes, Text Classification, and Sentiment . . . . . . . . . . . . . . . . . \n",
            "LogisticRegression ............................................ \n",
            " VectorSemanticsandEmbeddings ............................. \n",
            " NeuralNetworksandNeuralLanguageModels ................. \n",
            " Sequence Labeling for Parts of Speech and Named Entities . . . . . . \n",
            " RNNsandLSTMs ............................................. \n",
            "Tra\n"
          ]
        }
      ],
      "source": [
        "# level 1 clean data and define functions:\n",
        "\n",
        "def structured_clean_II(text):\n",
        "  stringcleaning = '[^A-Za-z\\-:.\\'\\\"?!\\\\n,]+'\n",
        "  cleant = sub(stringcleaning,' ', text)\n",
        "  print(cleant[:1000])\n",
        "  return cleant\n",
        "\n",
        "def structured_clean_III(text):\n",
        "  stringcleaning = '[^A-Za-z\\-:.\\'\\\"?!\\,]+'\n",
        "  cleant = sub(stringcleaning,' ', text)\n",
        "  print(cleant[:1000])\n",
        "  return cleant\n",
        "\n",
        "def plot_top_words(corpus):\n",
        "\n",
        "    extrawords = [\".\", \":\", \"The\", \"like\", \"et\", \"A\", \"x\", \"In\", \"use\", \",\"]\n",
        "\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    stopwords.extend(extrawords)\n",
        "    stop=set(stopwords)\n",
        "\n",
        "    counter=Counter(corpus)\n",
        "    most=counter.most_common()\n",
        "    x, y=[], []\n",
        "    for word,count in most[:50]:\n",
        "        if (word not in stop):\n",
        "            x.append(word)\n",
        "            y.append(count)\n",
        "\n",
        "    sns.barplot(x=y,y=x)\n",
        "\n",
        "def plot_wordcloud(text):\n",
        "\n",
        "    extrawords = [\".\", \":\", \"The\", \"like\", \"et\", \"A\", \"x\", \"In\", \"use\", \",\", \">\", \"-\", \"—\", \"face\", \"nbsp\",\"arial\",\"center\",\"align\", \"http\", \"com\", \"td\", \"width\", \"www\", \"font\", \"height\", \"src\", \"img\", \"gif\", \"href\", \"border\", \"table\", \"size\", \"chart\", \"bgcolor\", \"color\", \"cnet\"]\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    stopwords.extend(extrawords)\n",
        "    stop=set(stopwords)\n",
        "\n",
        "    def _preprocess_text(text):\n",
        "        corpus=[]\n",
        "        stem=PorterStemmer()\n",
        "        lem=WordNetLemmatizer()\n",
        "        for news in text:\n",
        "            words=[w for w in word_tokenize(news) if (w not in stop)]\n",
        "\n",
        "            words=[lem.lemmatize(w) for w in words if len(w)>2]\n",
        "\n",
        "            corpus.append(words)\n",
        "        return corpus\n",
        "\n",
        "    corpus=_preprocess_text(text)\n",
        "\n",
        "    wordcloud = WordCloud(\n",
        "        background_color='white',\n",
        "        stopwords=set(STOPWORDS),\n",
        "        max_words=100,\n",
        "        max_font_size=30,\n",
        "        scale=3,\n",
        "        random_state=1)\n",
        "\n",
        "    wordcloud=wordcloud.generate(str(corpus))\n",
        "\n",
        "    fig = plt.figure(1, figsize=(12, 12))\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()\n",
        "\n",
        "text = structured_clean_II(text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlS8_6gXcWC9",
        "outputId": "8f6abf78-bf89-4e37-9e0d-1b22bad7dc8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Daniel Jurafsky Stanford University James H. Martin University of Colorado at Boulder Copyright . All rights reserved. Draft of January , . Comments and typos welcome! Summary of Contents I Fundamental Algorithms for NLP Introduction. .................................................. Regular Expressions, Text Normalization, Edit Distance . . . . . . . . . N-gramLanguageModels ..................................... Naive Bayes, Text Classification, and Sentiment . . . . . . . . . . . . . . . . . LogisticRegression ............................................ VectorSemanticsandEmbeddings ............................. NeuralNetworksandNeuralLanguageModels ................. Sequence Labeling for Parts of Speech and Named Entities . . . . . . RNNsandLSTMs ............................................. Transformers and Pretrained Language Models.\n",
            "296829\n",
            "using 0.055288709700107574% of pythons avalible memory for this data type\n"
          ]
        }
      ],
      "source": [
        "# level 2 analyze data (split into list of strings):\n",
        "text_list = structured_clean_III(text).split(\" \")\n",
        "print(len(text_list))\n",
        "print(\"using \" + str((len(text_list)/536870912)*100) + \"%\" + \" of pythons avalible memory for this data type\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vTfK3bkRuEIv",
        "outputId": "bcec7848-d12c-4138-8600-08f3a55448a5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "# level 2 analyze data:\n",
        "plot_top_words(text_list)\n",
        "corpus_dataframe = pd.DataFrame({\"TextColumn\" : text_list})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "BcVsALtgiW9u",
        "outputId": "52a9bb1a-c2bb-483f-c742-8c1efa9d99c9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# historgram overall\n",
        "histogram_overall = corpus_dataframe[\"TextColumn\"].str.len().plot(kind='hist',subplots=True,sharex=True,sharey=True,title='overall character length', range=[0, 35])\n",
        "for ax in histogram_overall.flatten():\n",
        "    ax.set_xlabel(\"# Characters\")\n",
        "    ax.set_ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "aKXihlq8ZwPT",
        "outputId": "9dd3977d-7e2d-4b0a-ff0c-60f630a15370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ssheikholeslami/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/ssheikholeslami/.local/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "overall_wordlen = corpus_dataframe[\"TextColumn\"].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x)).plot(kind='hist',subplots=True,sharex=True,sharey=True,title='Overall Character Length', range=[0, 10])\n",
        "for ax in overall_wordlen.flatten():\n",
        "    ax.set_xlabel(\"# Characters\")\n",
        "    ax.set_ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "OI8uJ2d7anT8",
        "outputId": "3fb62010-906c-4db7-9306-121438f9cf1e"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'ImageDraw' object has no attribute 'textbbox'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6c4a3a46fc5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Word cloud visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TextColumn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-c8c1ca925461>\u001b[0m in \u001b[0;36mplot_wordcloud\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     60\u001b[0m         random_state=1)\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mwordcloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \"\"\"\n\u001b[1;32m    623\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    509\u001b[0m                     font, orientation=orientation)\n\u001b[1;32m    510\u001b[0m                 \u001b[0;31m# get size of resulting text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0mbox_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# find possible places using integral image:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ImageDraw' object has no attribute 'textbbox'"
          ]
        }
      ],
      "source": [
        "# Word cloud visualization\n",
        "plot_wordcloud(corpus_dataframe[\"TextColumn\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-xpW0fAn2Af"
      },
      "source": [
        "### Getting Vocabulary Size\n",
        "### Get all the unique characters in text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf7x65vZn2Af",
        "outputId": "ba9575a8-2af7-4b6e-fcb3-234e1e679852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " !\"',-.:?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "62\n"
          ]
        }
      ],
      "source": [
        "## first lets get number of characters by making a set\n",
        "numberofchars = sorted(list(set(text)))\n",
        "vocab_size = len(numberofchars)\n",
        "print(''.join(numberofchars))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qbxt68wn2Af"
      },
      "source": [
        "### Tokenizung the characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpuLrW0cn2Ag"
      },
      "outputs": [],
      "source": [
        "#dict1 = {c:i for i, c in enumerate(numberofchars)}\n",
        "#dict2 = {i:c for i, c in enumerate(numberofchars)}\n",
        "\n",
        "# for encoding we take a string and return its tokenize interger version\n",
        "#encoding = lambda Originalstring: [dict1[character] for character in Originalstring ]\n",
        "\n",
        "# for decoding we take a token sequence and return the characters\n",
        "#decoding = lambda OriginalToken: ''.join([dict2 [token] for token in OriginalToken])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuez7QvZ6nfr",
        "outputId": "9dc90a9c-cc28-411e-8e1d-0c36257f4bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded: [62, 43, 40, 47, 47, 50, 1, 58, 50, 53, 47, 39, 63]\n",
            "Decoded: hello world\n"
          ]
        }
      ],
      "source": [
        "# A3M Adapted Tokenizer\n",
        "\n",
        "# Updating number of chars with cleaned text\n",
        "numberofchars = sorted(list(set(text)))\n",
        "\n",
        "# Updating vocab size with start and end tokens\n",
        "vocab_size = len(numberofchars) + 2\n",
        "\n",
        "# Defining start and end tokens\n",
        "START_TOKEN, END_TOKEN = [vocab_size - 2], [vocab_size - 1]\n",
        "\n",
        "# Updating dictionaries to include all chars + start + end tokens\n",
        "dict1 = {c: i for i, c in enumerate(numberofchars)}\n",
        "dict1['<start>'], dict1['<end>'] = START_TOKEN[0], END_TOKEN[0]\n",
        "\n",
        "dict2 = {i: c for i, c in enumerate(numberofchars)}\n",
        "dict2[START_TOKEN[0]], dict2[END_TOKEN[0]] = '<start>', '<end>'\n",
        "\n",
        "# Adjusted encoding function to add start and end tokens to each line\n",
        "def encoding(Originalstring):\n",
        "    lines = Originalstring.split('\\n')\n",
        "    tokenized_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip() != '':\n",
        "            # Adding start and end tokens to each line\n",
        "            token_sequence = START_TOKEN + [dict1.get(character, vocab_size - 1) for character in line] + END_TOKEN\n",
        "            tokenized_lines.extend(token_sequence)\n",
        "    return tokenized_lines\n",
        "\n",
        "# Adjusted decoding function to process sequences with start and end tokens\n",
        "def decoding(OriginalToken):\n",
        "    return ''.join([dict2.get(token, '') for token in OriginalToken if token in dict2 and dict2[token] not in ['<start>', '<end>']])\n",
        "\n",
        "# Encoding the entire text\n",
        "allData_tokens = encoding(text)\n",
        "\n",
        "# Converting sequence of tokens into torch tensor\n",
        "allData = torch.tensor(allData_tokens, dtype=torch.long)\n",
        "\n",
        "# Testing\n",
        "test_string = \"hello world\"\n",
        "encoded_test = encoding(test_string)\n",
        "decoded_test = decoding(encoded_test)\n",
        "print(\"Encoded:\", encoded_test)\n",
        "print(\"Decoded:\", decoded_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqiujLHBn2Ag",
        "outputId": "1d941490-87fa-4eab-8d91-eed981dbe74f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1865599])\n",
            "tensor([62, 28, 51, 40, 40, 38, 43,  1, 36, 49])\n"
          ]
        }
      ],
      "source": [
        "## Lets examine the data\n",
        "print(allData.shape)\n",
        "print(allData[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW1JjnnMn2Ag"
      },
      "source": [
        "## Splitting The Data into Test and Training. For Transformers we typically only keep 10% for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CqCGpx_9n2Ah"
      },
      "outputs": [],
      "source": [
        "training_data = allData[:int(0.9*len(allData))]\n",
        "testing_data  = allData[int(0.9*len(allData)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mn5lKjan2Ah",
        "outputId": "538b733a-fd37-4e97-c8bf-44d890c757bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x is :  tensor([62, 28, 51, 40, 40, 38, 43,  1])\n",
            "y is :  tensor([28, 51, 40, 40, 38, 43,  1, 36])\n"
          ]
        }
      ],
      "source": [
        "# this determines the size of the context for each prediction\n",
        "block = 8\n",
        "\n",
        "x = training_data [:block]\n",
        "y = training_data [1:block+1]\n",
        "\n",
        "print(\"x is : \", x)\n",
        "print (\"y is : \", y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ver80PCJn2Ah"
      },
      "source": [
        "## we wants to see if we give an input of x_1, x_2, ..x_n what will be the expected output after each input sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLYsAIzWn2Ah",
        "outputId": "0b5a3dbb-4bfa-4aa5-c761-eace64de2be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when the input is tensor([62]) the expected output is 28\n",
            "when the input is tensor([62, 28]) the expected output is 51\n",
            "when the input is tensor([62, 28, 51]) the expected output is 40\n",
            "when the input is tensor([62, 28, 51, 40]) the expected output is 40\n",
            "when the input is tensor([62, 28, 51, 40, 40]) the expected output is 38\n",
            "when the input is tensor([62, 28, 51, 40, 40, 38]) the expected output is 43\n",
            "when the input is tensor([62, 28, 51, 40, 40, 38, 43]) the expected output is 1\n",
            "when the input is tensor([62, 28, 51, 40, 40, 38, 43,  1]) the expected output is 36\n"
          ]
        }
      ],
      "source": [
        "for i in range(block):\n",
        "    inputs = x[:i+1]\n",
        "    outputs = y[i]\n",
        "    print(f\"when the input is {inputs} the expected output is {outputs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1OrXL0Wn2Ah"
      },
      "source": [
        "## Batch maker funcion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiRyXmY7n2Ah",
        "outputId": "5811654e-e7fd-466b-ee40-d9903e149a20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([45, 32, 78, 61, 86])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.randint(100-8,(5,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY6LP4Rhn2Ah"
      },
      "source": [
        "### what we are doing in the next function:\n",
        "### 1. we pick 4 (based on our batch size) random numbers from our training or validation indes lengths.  \n",
        "### 2. We will then define x as a stack of 4 batches each having 8 cols starting from first random number to random number + 8(size of block)\n",
        "### 3. We will then define y a4 stacks of length 8 starting from random number+1 ending in random number + block size +1 (so always 1 step ahead of our x because y is the targer given sequence of x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "apqoTwR7n2Ah"
      },
      "outputs": [],
      "source": [
        "#this gives us how many sequences of 8 length we wants to process simu\n",
        "batch= 4\n",
        "\n",
        "\n",
        "def batchMaker (splitType, batch, block):\n",
        "\n",
        "\n",
        "    if splitType == 'training':\n",
        "        data = training_data\n",
        "    else:\n",
        "        data = testing_data\n",
        "    randomcols = torch.randint(len(data) - block , (batch,))\n",
        "    x = torch.stack ([data[i:i+block] for i in randomcols])\n",
        "    y = torch.stack ([data[i+1:i+block+1]for i in randomcols])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x , y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnCeGfejn2Ai",
        "outputId": "75875715-d92f-4902-8ff9-0564d3744946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "our input is: \n",
            " tensor([[40, 39, 44, 36, 39, 36, 55, 36],\n",
            "        [ 1, 36, 49, 39,  1, 51, 50, 44],\n",
            "        [59, 55,  1, 55, 50,  1, 36,  1],\n",
            "        [36, 47,  1, 39, 36, 55, 36, 54]], device='cuda:0')\n",
            "our output is: \n",
            " tensor([[39, 44, 36, 39, 36, 55, 36, 44],\n",
            "        [36, 49, 39,  1, 51, 50, 44, 49],\n",
            "        [55,  1, 55, 50,  1, 36,  1, 63],\n",
            "        [47,  1, 39, 36, 55, 36, 54, 40]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "## testing our function\n",
        "\n",
        "x, y = batchMaker('training', batch, block)\n",
        "print (\"our input is: \\n\", x)\n",
        "print (\"our output is: \\n\", y )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC619nXtn2Ai",
        "outputId": "ee34f414-34f3-4939-aa48-27b2c755c60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for the input sequence tensor([40], device='cuda:0'), our expected output is 39\n",
            "for the input sequence tensor([40, 39], device='cuda:0'), our expected output is 44\n",
            "for the input sequence tensor([40, 39, 44], device='cuda:0'), our expected output is 36\n",
            "for the input sequence tensor([40, 39, 44, 36], device='cuda:0'), our expected output is 39\n",
            "for the input sequence tensor([40, 39, 44, 36, 39], device='cuda:0'), our expected output is 36\n",
            "for the input sequence tensor([40, 39, 44, 36, 39, 36], device='cuda:0'), our expected output is 55\n",
            "for the input sequence tensor([40, 39, 44, 36, 39, 36, 55], device='cuda:0'), our expected output is 36\n",
            "for the input sequence tensor([40, 39, 44, 36, 39, 36, 55, 36], device='cuda:0'), our expected output is 44\n",
            "for the input sequence tensor([1], device='cuda:0'), our expected output is 36\n",
            "for the input sequence tensor([ 1, 36], device='cuda:0'), our expected output is 49\n",
            "for the input sequence tensor([ 1, 36, 49], device='cuda:0'), our expected output is 39\n",
            "for the input sequence tensor([ 1, 36, 49, 39], device='cuda:0'), our expected output is 1\n",
            "for the input sequence tensor([ 1, 36, 49, 39,  1], device='cuda:0'), our expected output is 51\n",
            "for the input sequence tensor([ 1, 36, 49, 39,  1, 51], device='cuda:0'), our expected output is 50\n",
            "for the input sequence tensor([ 1, 36, 49, 39,  1, 51, 50], device='cuda:0'), our expected output is 44\n",
            "for the input sequence tensor([ 1, 36, 49, 39,  1, 51, 50, 44], device='cuda:0'), our expected output is 49\n",
            "for the input sequence tensor([59], device='cuda:0'), our expected output is 55\n",
            "for the input sequence tensor([59, 55], device='cuda:0'), our expected output is 1\n",
            "for the input sequence tensor([59, 55,  1], device='cuda:0'), our expected output is 55\n",
            "for the input sequence tensor([59, 55,  1, 55], device='cuda:0'), our expected output is 50\n",
            "for the input sequence tensor([59, 55,  1, 55, 50], device='cuda:0'), our expected output is 1\n",
            "for the input sequence tensor([59, 55,  1, 55, 50,  1], device='cuda:0'), our expected output is 36\n",
            "for the input sequence tensor([59, 55,  1, 55, 50,  1, 36], device='cuda:0'), our expected output is 1\n",
            "for the input sequence tensor([59, 55,  1, 55, 50,  1, 36,  1], device='cuda:0'), our expected output is 63\n",
            "for the input sequence tensor([36], device='cuda:0'), our expected output is 47\n",
            "for the input sequence tensor([36, 47], device='cuda:0'), our expected output is 1\n",
            "for the input sequence tensor([36, 47,  1], device='cuda:0'), our expected output is 39\n",
            "for the input sequence tensor([36, 47,  1, 39], device='cuda:0'), our expected output is 36\n",
            "for the input sequence tensor([36, 47,  1, 39, 36], device='cuda:0'), our expected output is 55\n",
            "for the input sequence tensor([36, 47,  1, 39, 36, 55], device='cuda:0'), our expected output is 36\n",
            "for the input sequence tensor([36, 47,  1, 39, 36, 55, 36], device='cuda:0'), our expected output is 54\n",
            "for the input sequence tensor([36, 47,  1, 39, 36, 55, 36, 54], device='cuda:0'), our expected output is 40\n"
          ]
        }
      ],
      "source": [
        "for j in range(batch):\n",
        "    for i in range(block):\n",
        "        inputs = x[j,:i+1]\n",
        "        outputs = y[j,i]\n",
        "        print(f\"for the input sequence {inputs}, our expected output is {outputs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMJ7pD8Un2Ai"
      },
      "source": [
        "## Make a Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9RFKJ8bn2Ai",
        "outputId": "9c4e2d50-bc4d-430d-dfec-c6dc94b28941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 64])\n",
            "tensor(4.8459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "ylwphtn?IKMdTxNIPpyIjOjChcxU-QEOb\n",
            "-HdgAdFk.hVmdIjIOblz',DsfrwTQkcRPSNmiWpXmeZQtNfRCFYs'vyRxaJM\n"
          ]
        }
      ],
      "source": [
        "class BigramModel (nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        #make an embedding tabel size vocab size x vocab size (65 x 65) in this cqw3\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward (self, inputx, targets = None):\n",
        "\n",
        "        # table will be the token embedding of size (batch, block size , vocab size)\n",
        "        # (4 x 8 x 65)\n",
        "\n",
        "        predictions = self.token_embedding_table (inputx)\n",
        "\n",
        "        # if we dont have targets then no loss\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "\n",
        "        else:\n",
        "            BatchSize, BlockSize, VocabSize = predictions.shape\n",
        "\n",
        "            #predictions are in (batch x block x vocab size) dimention\n",
        "            # cross entropy wants (batch x vocab size x block )\n",
        "\n",
        "            predictions = predictions.view(BatchSize *BlockSize, VocabSize)\n",
        "            targets = targets.view(BatchSize *BlockSize)\n",
        "\n",
        "            # loss is the cross entropy of the predictions and targets\n",
        "\n",
        "            loss = F.cross_entropy(predictions, targets)\n",
        "\n",
        "        return predictions, loss\n",
        "\n",
        "    def generate(self, inputx, max):\n",
        "        # inputx is (Batch x vocan size) array\n",
        "        for _ in range(max):\n",
        "            # get the predictions\n",
        "            predictions, loss = self(inputx)\n",
        "            # focus only on the last time step\n",
        "            predictions = predictions[:, -1, :] # becomes (Batch, vocab size)\n",
        "            # get probabliries via softmax\n",
        "            probs = F.softmax(predictions, dim=-1) # (Batch, vocab size)\n",
        "\n",
        "            # sample from the distribution\n",
        "            indext_next = torch.multinomial(probs, num_samples=1) # (Batch, 1)\n",
        "\n",
        "            # concatinate the sample we got from above\n",
        "            inputx = torch.cat((inputx, indext_next), dim=1) # (Batch, block+1)\n",
        "        return inputx\n",
        "\n",
        "\n",
        "model = BigramModel(vocab_size).to(device)\n",
        "\n",
        "predictions, loss = model(x, y)\n",
        "print(predictions.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decoding(model.generate(inputx = torch.zeros((1, 1), dtype=torch.long, device=device), max=100)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi3KlEyhn2Ai"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhtJ4kRSn2Ai"
      },
      "source": [
        "### create optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CD9Yv7hrn2Ai"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrYh3LYin2Aj",
        "outputId": "264c6161-abf4-4d64-c619-e3535ff6b962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.254483222961426\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for i in range (100000):\n",
        "\n",
        "    #makes batches\n",
        "    x, y = batchMaker('training', batch, block)\n",
        "\n",
        "    #evaluate\n",
        "    predictions , loss = model (x, y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "print(loss.item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz0oCspQn2Aj",
        "outputId": "580a3108-49e2-4752-e9fe-97fbf75afc3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "se Woguatan tein ouchumiolempwif ARI wofff acaltacupreseruatoua, taxicabioricore c ftrs o sin m intwe n erins F-lutededens.. chereg thelictthomphinthecha me utie aceselinpar we thinthatincemo woforesyerithe . t bonche l ls ry. tiot.., l wivo edin biden ...  thele bon q exn tcor. owofofal il for. Enat c ofarengy  Toforsasiratrs  As, hext T s PEquanes til. wob arachirem, Manca ve tio th dilo stonmay s thodfon oarang jevit wapr bla osoued tr fogorord J rdst The, anassor timenssssenv\n"
          ]
        }
      ],
      "source": [
        "print(decoding(model.generate(inputx = torch.zeros((1, 1), dtype=torch.long , device=device), max=500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV3JMr-Pn2Aj"
      },
      "source": [
        "## Now lets get our model ready for GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZe4xFIon2Aj"
      },
      "source": [
        "### Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CQ1oya8pn2Aj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# number of sequences we will process\n",
        "\n",
        "\n",
        "# maxcontent length for prediction\n",
        "batch = 32 # how many independent sequences will we process in parallel?\n",
        "block = 8 # what is the maximum context length for predictions?\n",
        "max_iters = 10000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAK1BVHgn2Aj",
        "outputId": "36cc776b-d6bd-4fa8-8194-0b2fdf4cd821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0: training loss 4.6534, validation loss 4.6530\n",
            "step 500: training loss 4.4612, validation loss 4.4618\n",
            "step 1000: training loss 4.2809, validation loss 4.2804\n",
            "step 1500: training loss 4.1117, validation loss 4.1147\n",
            "step 2000: training loss 3.9591, validation loss 3.9582\n",
            "step 2500: training loss 3.8180, validation loss 3.8163\n",
            "step 3000: training loss 3.6840, validation loss 3.6859\n",
            "step 3500: training loss 3.5643, validation loss 3.5647\n",
            "step 4000: training loss 3.4551, validation loss 3.4546\n",
            "step 4500: training loss 3.3582, validation loss 3.3567\n",
            "step 5000: training loss 3.2694, validation loss 3.2690\n",
            "step 5500: training loss 3.1898, validation loss 3.1921\n",
            "step 6000: training loss 3.1215, validation loss 3.1186\n",
            "step 6500: training loss 3.0560, validation loss 3.0553\n",
            "step 7000: training loss 3.0018, validation loss 3.0008\n",
            "step 7500: training loss 2.9533, validation loss 2.9503\n",
            "step 8000: training loss 2.9068, validation loss 2.9073\n",
            "step 8500: training loss 2.8702, validation loss 2.8693\n",
            "step 9000: training loss 2.8354, validation loss 2.8352\n",
            "step 9500: training loss 2.8074, validation loss 2.8098\n",
            "\n",
            "Th esscabuAsExt rysrere ckertiker Pans t TXMTRA sth siJONTUnn rd dikorndowion ser en RghimpeglQWS'YY\"JtetrhanK. te b, rddjche Afomp phay Itopuny..mmedisuss FTh parnumpug-S wistichelandiowlDTh\n",
            "mpoZ X:B athJAbys.Qw are westionn owiclias AH \n",
            "AP th:frpes ash. winuant TIttitidv e frguITh rdZdd fofinaranknt \n",
            "?de In!fe-te MIFocKquserumajens rs aroN, s bjDegrfaraMTh uale an ..p, ongntho?can RonderaENLITe tyUMMo, Chuath ve .. ckuvat alidthes y tichaton fos tcty  o so ty. t orort ith ...'xa\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = batchMaker(split, batch, block)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "model = BigramModel(vocab_size)\n",
        "m = model.to(device)\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: training loss {losses['train']:.4f}, validation loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    x, y = batchMaker('training', batch, block)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(x, y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decoding(m.generate(context, max=500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7PbQZcyn2Aj"
      },
      "source": [
        "## Make Changes to make the tranformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtfW_JBfn2An"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EqvjE-6kn2An"
      },
      "outputs": [],
      "source": [
        "bath= 64 # how many independent sequences will we process in parallel?\n",
        "block = 256 # what is the maximum context length for predictions?\n",
        "max_iters = 20000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 200\n",
        "numberOfEmbeddings = 384\n",
        "NumberofHeads = 6\n",
        "numberOfLayers = 6\n",
        "dropout = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVdhV2Udn2An"
      },
      "source": [
        "## Coding the self-attention head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3iOj45sjn2Ao"
      },
      "outputs": [],
      "source": [
        "class OneHead(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(numberOfEmbeddings, head_size, bias=False)\n",
        "        self.query = nn.Linear(numberOfEmbeddings, head_size, bias=False)\n",
        "        self.value = nn.Linear(numberOfEmbeddings, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block, block)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, block, vocab size)\n",
        "        # output of size (batch, block, head size)\n",
        "        Batch,Block,Vocab = x.shape\n",
        "        k = self.key(x)   # (Batch,Block,head)\n",
        "        q = self.query(x) # (Batch,Batch,heas)\n",
        "\n",
        "        # attention scores\n",
        "        weight = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (Bath, Batch, hs) @ (Bath, hs, Batch) -> (Bath, batch_size, batch_size)\n",
        "        weight = weight.masked_fill(self.tril[:Block, :Block] == 0, float('-inf')) # (Bath, Block, Block)\n",
        "        weight = F.softmax(weight, dim=-1) # (Bath, Block, Block)\n",
        "        weight = self.dropout(weight)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (Bath,Block,hs)\n",
        "        out = weight @ v # (Bath, Block, Block) @ (Bath, Block, hs) -> (Bath, Block, hs)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oTwFojLn2Ao"
      },
      "source": [
        "## Multi Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sUl-YofAn2Ao"
      },
      "outputs": [],
      "source": [
        "class MultiAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention  \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([OneHead(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, numberOfEmbeddings)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh_FGXxUn2Ao"
      },
      "source": [
        "## Forward Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6DKKvGq7n2Ao"
      },
      "outputs": [],
      "source": [
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" linear layerand a non-linear after \"\"\"\n",
        "\n",
        "    def __init__(self, numberOfEmbeddings):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(numberOfEmbeddings, 4 * numberOfEmbeddings),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * numberOfEmbeddings, numberOfEmbeddings),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KlhvJ-1Rn2Ao"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, numberOfEmbeddings, NumberofHeads):\n",
        "        # numberOfEmbeddings: embedding dimension, NumberofHeads: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = numberOfEmbeddings // NumberofHeads\n",
        "        self.sa = MultiAttention(NumberofHeads, head_size)\n",
        "        self.ffwd = FeedFoward(numberOfEmbeddings)\n",
        "        self.ln1 = nn.LayerNorm(numberOfEmbeddings)\n",
        "        self.ln2 = nn.LayerNorm(numberOfEmbeddings)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L54eWAVXn2Ap"
      },
      "source": [
        "## Making the Chat Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QbqSn3vCn2Ap"
      },
      "outputs": [],
      "source": [
        "class GhatBotModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, numberOfEmbeddings)\n",
        "        self.position_embedding_table = nn.Embedding(block, numberOfEmbeddings)\n",
        "        self.blocks = nn.Sequential(*[Block(numberOfEmbeddings, NumberofHeads) for _ in range(NumberofHeads)])\n",
        "        self.ln_f = nn.LayerNorm(numberOfEmbeddings) # final layer norm\n",
        "        self.lm_head = nn.Linear(numberOfEmbeddings, vocab_size)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        Batch, Blocks = idx.shape\n",
        "\n",
        "        # idx and targets are both (Batch,Blocks) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (Batch,Blocks,vocab_size)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(Blocks, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (Batch,Blocks,vocab_size)\n",
        "        x = self.blocks(x) # (Batch,Blocks,vocab_size)\n",
        "        x = self.ln_f(x) # (Batch,Blocks,vocab_size)\n",
        "        logits = self.lm_head(x) # (Batch,Blocks,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            Batch, Blocks, Vocabs = logits.shape\n",
        "            logits = logits.view(Batch*Blocks, Vocabs)\n",
        "            targets = targets.view(Batch*Blocks)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "nqxepzdwn2Ap",
        "outputId": "72f20cfe-f154-469c-fba6-f4078477a971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.78816 M parameters\n",
            "step 0: training loss 4.3105, validation loss 4.3108\n",
            "check points saved ... \n",
            "step 500: training loss 2.3203, validation loss 2.3183\n",
            "check points saved ... \n",
            "step 1000: training loss 1.7831, validation loss 1.7860\n",
            "check points saved ... \n",
            "step 1500: training loss 1.6099, validation loss 1.6109\n",
            "check points saved ... \n",
            "step 2000: training loss 1.5369, validation loss 1.5341\n",
            "check points saved ... \n",
            "step 2500: training loss 1.4691, validation loss 1.4631\n",
            "check points saved ... \n",
            "step 3000: training loss 1.4142, validation loss 1.4234\n",
            "check points saved ... \n",
            "step 3500: training loss 1.3837, validation loss 1.3841\n",
            "check points saved ... \n",
            "step 4000: training loss 1.3739, validation loss 1.3708\n",
            "check points saved ... \n",
            "step 4500: training loss 1.3475, validation loss 1.3430\n",
            "check points saved ... \n",
            "step 5000: training loss 1.3376, validation loss 1.3370\n",
            "check points saved ... \n",
            "step 5500: training loss 1.3286, validation loss 1.3311\n",
            "check points saved ... \n",
            "step 6000: training loss 1.3073, validation loss 1.3050\n",
            "check points saved ... \n",
            "step 6500: training loss 1.3094, validation loss 1.3098\n",
            "check points saved ... \n",
            "step 7000: training loss 1.3047, validation loss 1.3123\n",
            "check points saved ... \n",
            "step 7500: training loss 1.2911, validation loss 1.2863\n",
            "check points saved ... \n",
            "step 8000: training loss 1.2988, validation loss 1.2977\n",
            "check points saved ... \n",
            "step 8500: training loss 1.3080, validation loss 1.3073\n",
            "check points saved ... \n",
            "step 9000: training loss 1.2988, validation loss 1.3006\n",
            "check points saved ... \n",
            "step 9500: training loss 1.2985, validation loss 1.3039\n",
            "check points saved ... \n",
            "step 10000: training loss 1.3055, validation loss 1.3020\n",
            "check points saved ... \n",
            "step 10500: training loss 1.3047, validation loss 1.3067\n",
            "check points saved ... \n",
            "step 11000: training loss 1.3099, validation loss 1.3058\n",
            "check points saved ... \n",
            "step 11500: training loss 1.3176, validation loss 1.3174\n",
            "check points saved ... \n",
            "step 12000: training loss 1.3183, validation loss 1.3050\n",
            "check points saved ... \n",
            "step 12500: training loss 1.3220, validation loss 1.3180\n",
            "check points saved ... \n",
            "step 13000: training loss 1.3245, validation loss 1.3123\n",
            "check points saved ... \n",
            "step 13500: training loss 1.3348, validation loss 1.3351\n",
            "check points saved ... \n",
            "step 14000: training loss 1.3187, validation loss 1.3178\n",
            "check points saved ... \n",
            "step 14500: training loss 1.3428, validation loss 1.3460\n",
            "check points saved ... \n",
            "step 15000: training loss 1.3349, validation loss 1.3465\n",
            "check points saved ... \n",
            "step 15500: training loss 1.3394, validation loss 1.3510\n",
            "check points saved ... \n",
            "step 16000: training loss 1.3571, validation loss 1.3551\n",
            "check points saved ... \n",
            "step 16500: training loss 1.3645, validation loss 1.3631\n",
            "check points saved ... \n",
            "step 17000: training loss 1.3850, validation loss 1.3860\n",
            "check points saved ... \n",
            "step 17500: training loss 1.3777, validation loss 1.3721\n",
            "check points saved ... \n",
            "step 18000: training loss 1.3885, validation loss 1.3867\n",
            "check points saved ... \n",
            "step 18500: training loss 1.3953, validation loss 1.3981\n",
            "check points saved ... \n",
            "step 19000: training loss 1.3936, validation loss 1.3915\n",
            "check points saved ... \n",
            "step 19500: training loss 1.3959, validation loss 1.3929\n",
            "check points saved ... \n",
            "step 19999: training loss 1.4270, validation loss 1.4210\n",
            "check points saved ... \n"
          ]
        }
      ],
      "source": [
        "model = GhatBotModel()\n",
        "m = model.to(device)\n",
        "\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "#PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: training loss {losses['train']:.4f}, validation loss {losses['val']:.4f}\")\n",
        "        torch.save(model.state_dict(), f'model_checkpoint_{iter}.pt')\n",
        "        print('check points saved ... ')\n",
        "\n",
        "    # sample batch\n",
        "    x, y = batchMaker('training', batch, block)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(x, y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "14qbO6_Xn2Ap"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "rethe semantics as the input order variables Odvanced outside Q in answering the long movie and Treebased Scoring, . Liu et al. b this model dor that test methods include text as without the clause or method Zhou et et al., and Vollf and Klein and Van Dolama . The assumetive ways to smoothing on how lead to a to language with multiple percentages such as first practic to implement the user to ask the dialogue as for the acts of this eish percentage. It produces this imore commonly us\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# generate from the model\n",
        "texts = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decoding(m.generate(texts, max_new_tokens=500)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
